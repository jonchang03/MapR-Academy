# to launch pyspark shell /opt/mapr/spark/spark-<version>/bin/Pyspark
# import SQLContext and pyspark SQL functions
from pyspark.sql import SQLContext, Row
import pyspark.sql.functions as func

# 2. create a SQLContext
sqlContext = SQLContext(sc)

# 4. Create an RDD “inputRDD” using sc.textFile to load the data from /user/user01/data/aucitondata.csv.
# Also, make sure that you split the input file based on the separator.
inputRDD = sc.textFile("/user/user01/data/auctiondata.csv").map(lambda l: l.split(","))

# 5. map the inputRDD to the case class
auctions = inputRDD.map(lambda p:Row(auctionid=p[0], bid=float(p[1]), bidtime=float(p[2]), bidder=p[3], bidrate=int(p[4]), openbid=float(p[5]), price=float(p[6]), itemtype=p[7], dtl=int(p[8])))

# 6. Infer the schema, and register the DataFrame as a table.
auctiondf = sqlContext.createDataFrame(auctions)
auctiondf.registerTempTable("auctions")

# 7. What action can you use to check the data in the DataFrame.
auctiondf.show()

# 8. What DataFrame function could you use to see the schema for the DataFrame?
auctiondf.printSchema()

# Lab 2.2.2 Inspect the Data
# 1. What is the total number of bids?
totbids = auctiondf.count()
print totbids
#10654

# 2. What is the number of distinct auctions?
totalauctions = auctiondf.select("auctionid").distinct().count()u
print total auctions
#627

# 3. What is the number of distinct itemtypes?
itemtypes = auctiondf.select("itemtype").distinct().count()
print itemtypes
#3

# 4. We would like a count of bids per auction and the item type (as shown below).
# How would you do this? (HINT: Use groupBy.)
auctiondf.groupBy("itemtype","auctionid").count().show()

# 5. For each auction item and item type, we want the max, min and average number of bids.
auctiondf.groupBy("itemtype","auctionid").count().agg(func.min("count"), func.max("count"), func.avg("count")).show()

# 6. For each auction item and item type, we want the following information (minimum bid, maximum bid, average bid):
# (HINT: Use groupBy and agg)
auctiondf.groupBy("itemtype", "auctionid").agg(func.min("bid"), func.max("bid"), func.avg("bid")).show()

# 7. What is the number of auctions with final price greater than 200?
auctiondf.filter(auctiondf.price>200).count()
#7685L

# 8. We want to run some basic statistics on all auctions that are of type xbox.
What is one way of doing this? (HINT: We have registered the DataFrame as a table so we can use sql queries.
The result will be a DataFrame and we can apply actions to it.)
xboxes = sqlContext.sql("SELECT auctionid, itemtype,bid,price,openbid FROM auctions WHERE itemtype = 'xbox'")
xboxes.show()

# 9. We want to compute basic statistics on the final price (price column). What action could we use?
xboxes.describe("price").show()
#summary price
#count   2784
#mean    144.27594109195397
#stddev  72.93472700540288
#min     31.0
#max     501.77
